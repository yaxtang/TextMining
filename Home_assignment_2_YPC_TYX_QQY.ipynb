{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home assignment 2\n",
    "\n",
    "You should work on the assignement in groups/teams of 3 participants. Submissions of single students will not be accepted! Please use the Forum in case of doubt in order to find team mates!\n",
    "\n",
    "Upload your solution as a jupyter notebook to moodle by Tuesday, 7th of January 23:55h. (The deadline is strict)\n",
    "It is sufficient if one student of each team submits the solution.\n",
    "\n",
    "\n",
    "You should add comments to your code where necessary and print the relevant results. You should also always test your code on self-chosen examples.\n",
    "\n",
    "Do not forget to specify the (First_name, Last_name, student_id (matrikelnummer)) of all contributing students in the jupyter notebook here:\n",
    "\n",
    "Student 1: `Yaping, Chen, 379645`\n",
    "\n",
    "Student 2: `Qingqing, Yang, 393415`\n",
    "\n",
    "Student 3: `Yaxin, tang, 402317`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing GloVe\n",
    "In this task you will implement the glove algorithm using PyTorch. (One advantage is that you need not calculate gradient by hand, but you can take advantage of the autograd module). The task will require implementation of certain functions, which we look into step-by-step:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for word to index mapping. Since the model won't be able to take strings as input we will convert them into indices. The function will generate a mapping  w2i which uses words as keys and corresponding indices as values e.g., `w2i['walk'] = 42`. As Preprocessing, remove all punctuations and convert all words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def word2indexMapping(textfile):\n",
    "    w2i = {}\n",
    "    text = [] # sequence of words as they appear in the text after removing punctuations\n",
    "    \n",
    "    #Preprocessing\n",
    "    textfile = textfile.replace('\\n', ' ').strip()\n",
    "    translator = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "    text = textfile.translate(translator)\n",
    "    text = text.lower()\n",
    "    \n",
    "    #Mapping\n",
    "    test_list = word_tokenize(text)\n",
    "    w2i = {k: test_list.index(k) for k in test_list}\n",
    "\n",
    "    return w2i, text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for calculating a two dimensional matrix $X_{ij}$ which is the number of times word $j$ occurred in the context of word $i$. The size of the context window $k$ (as a number of words, $k=2$ describes that the context contains the two words before and the two words after the central word) is also an argument of the function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrenceFreq(text, w2i, k): # text is a sequence of words ordered as they appear in the text\n",
    "    # note that there is no notion of sentence here...\n",
    "    \n",
    "    X_ij =  np.zeros((len(w2i), len(w2i)))\n",
    "    \n",
    "    # write your code snippet here...\n",
    "    text = text.split(\" \")\n",
    "    tokens = list(w2i.keys())\n",
    "    token_ids = list(w2i.values())\n",
    "    context_ids = [] #context for each word\n",
    "    for center_id in token_ids:\n",
    "        #left part context for given center\n",
    "        x = max(0, center_id - k)\n",
    "        #right part context for given center_id\n",
    "        y = min(len(text) - 1, center_id + k)\n",
    "        context_ids.append(list(range(x, y + 1)))\n",
    "        contexts_len = len(context_ids)\n",
    "    #print(context_ids)\n",
    "    count, y = 0, 0 #y represent for index for each center word\n",
    "    for center_i in tokens:\n",
    "        for i in range(0,contexts_len): #two demension list interation by i, j\n",
    "            count = 0\n",
    "            for j in range(0,len(context_ids[i])):\n",
    "                if center_i!=text[context_ids[i][j]]:\n",
    "                    j=j+1\n",
    "                else: count=count+1\n",
    "            X_ij[i][y]=count\n",
    "            i+=1\n",
    "        y+=1\n",
    "    return X_ij"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a GloVe model class with parameters $w$, $\\hat w$, $b$ and $\\hat b$. For a particular pair of words $i$, $j$, your forward function should implement $w_{i}^{T}\\hat w_{j} + b_{i} + \\hat b_{j}$. Assume a dimension of embedding to be $d$ which you will specify when creating an instance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Glove(nn.Module):\n",
    "    # write your model class here....\n",
    "    def __init__(self, text, dimension):\n",
    "        super().__init__()\n",
    "        self.dimension = dimension\n",
    "        self.vocab_size = len(text) #text after preprocess, so only unique words contained\n",
    "        #Word vector matrix V * d\n",
    "        #All elements are initialized randomly in the range (-0.5,0.5]\n",
    "        self.w_1 = nn.Parameter((torch.randn(self.vocab_size, dimension) - 0.5) / float(dimension + 1), requires_grad=True)\n",
    "        self.w_2 = nn.Parameter((torch.randn(self.vocab_size, dimension) - 0.5) / float(dimension + 1), requires_grad=True)\n",
    "        #bias array size V\n",
    "        #initialized randomly in the range (-0.5, 0.5]\n",
    "        self.b_1 = nn.Parameter((torch.randn(self.vocab_size) - 0.5) / float(dimension + 1), requires_grad=True)\n",
    "        self.b_2 = nn.Parameter((torch.randn(self.vocab_size) - 0.5) / float(dimension + 1), requires_grad=True)\n",
    "\n",
    "        \n",
    "    def forward(self, i, j):\n",
    "        cost = self.w_1[i].dot(self.w_2[j]) + self.b_1[i] + self.b_2[j]#first transpose, then multiply, add\n",
    "        return cost\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that implements the weighting function $f(X_{ij})$\n",
    "\n",
    "$f(x) = (\\frac{x}{100})^{\\frac{3}{4}}$ if x<100 \n",
    "\n",
    "$f(x) = 1 $ otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightFunction(X_ij, i, j):\n",
    "    f = 0\n",
    "    # write your code snippet here\n",
    "    x_max = 100\n",
    "    alpha = 0.75\n",
    "    f = (X_ij[i][j] / x_max) ** alpha if X_ij[i][j] < x_max else 1\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a train function to train the model using stochastic gradient descent. Your each training instance would be a word-context pair ($i$, $j$) and the corresponding loss function would be \n",
    "\n",
    "$f(X_{ij})(w_{i}^{T}\\hat w_{j} + b_{i} + \\hat b_{j} - log(1 + X_{ij}))^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import math\n",
    "\n",
    "def loss_func(X_ij, i, j):\n",
    "    return weightFunction(X_ij, i, j)*((model.forward(i, j)-math.log(1+X_ij[i][j]))**2)\n",
    "\n",
    "def train(model, X_ij, learning_rate=0.001, epochs=5):\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001) # use Adam as your optimizer\n",
    "    for _ in range(epochs):\n",
    "        # train across each word-conext pair\n",
    "        for i in range(len(X_ij)): \n",
    "            for j in range(len(X_ij[0])):\n",
    "                if X_ij[i][j] > 0:     #posive co-occurence frequency\n",
    "                    loss = loss_func(X_ij, i, j)# calculate loss\n",
    "                    loss.backward() # backpropagate for every training example\n",
    "                    opt.step()\n",
    "                    opt.zero_grad()\n",
    "    return model.w_1, model.w_2, model.b_1, model.b_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to generate embeddings given a word. The embedding of a word with index $i$ would $w_i + \\hat w_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbedding(model, word):\n",
    "    # write your code snippet here...\n",
    "    index = w2i[word]\n",
    "    embed = model.w_1[index] + model.w_2[index]\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the individual components together to train a Glove model from the given text file  'shakespeare-caesar.txt' with dimension 200 and a context window of 5.\n",
    "Manually inspect nearest neigbors for some self-picked words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original result.....\n",
      "Parameter containing:\n",
      "tensor([[-0.0030, -0.0014, -0.0021,  ..., -0.0021, -0.0115,  0.0059],\n",
      "        [ 0.0016,  0.0042, -0.0156,  ...,  0.0027, -0.0012, -0.0066],\n",
      "        [-0.0094, -0.0030, -0.0004,  ..., -0.0125, -0.0015, -0.0007],\n",
      "        ...,\n",
      "        [ 0.0021, -0.0030, -0.0038,  ...,  0.0022,  0.0036, -0.0049],\n",
      "        [-0.0067, -0.0052,  0.0025,  ..., -0.0013, -0.0048, -0.0064],\n",
      "        [-0.0059, -0.0104, -0.0057,  ..., -0.0048,  0.0015, -0.0057]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([[-0.0006,  0.0004,  0.0017,  ..., -0.0072,  0.0102, -0.0006],\n",
      "        [ 0.0064, -0.0204, -0.0012,  ..., -0.0045,  0.0030, -0.0006],\n",
      "        [-0.0035,  0.0024,  0.0054,  ...,  0.0068, -0.0092,  0.0080],\n",
      "        ...,\n",
      "        [-0.0037, -0.0058,  0.0030,  ..., -0.0030, -0.0003, -0.0039],\n",
      "        [ 0.0087, -0.0012,  0.0058,  ...,  0.0026, -0.0051, -0.0025],\n",
      "        [-0.0074,  0.0025, -0.0082,  ...,  0.0003,  0.0015,  0.0007]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([-0.0044, -0.0056, -0.0086, -0.0036,  0.0022, -0.0011, -0.0029, -0.0072,\n",
      "        -0.0031, -0.0084,  0.0053, -0.0027,  0.0010, -0.0013, -0.0014, -0.0071,\n",
      "         0.0012,  0.0027, -0.0035, -0.0002, -0.0006, -0.0022, -0.0010, -0.0085,\n",
      "         0.0006, -0.0009, -0.0092, -0.0020, -0.0009,  0.0008, -0.0079, -0.0008,\n",
      "        -0.0015, -0.0029, -0.0005, -0.0020, -0.0036,  0.0041, -0.0017, -0.0051,\n",
      "        -0.0019,  0.0074, -0.0013,  0.0017,  0.0011, -0.0099, -0.0076, -0.0061,\n",
      "        -0.0064, -0.0025, -0.0032,  0.0037,  0.0013, -0.0029, -0.0023,  0.0041],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([-0.0016, -0.0026,  0.0002, -0.0070,  0.0017, -0.0082,  0.0008, -0.0068,\n",
      "        -0.0012,  0.0038, -0.0040,  0.0006, -0.0040,  0.0008,  0.0045,  0.0009,\n",
      "        -0.0058, -0.0097, -0.0004, -0.0117,  0.0036, -0.0013,  0.0068, -0.0063,\n",
      "        -0.0074, -0.0053,  0.0081, -0.0176,  0.0013, -0.0018, -0.0011, -0.0028,\n",
      "         0.0027, -0.0024, -0.0052, -0.0045, -0.0009, -0.0138, -0.0017,  0.0002,\n",
      "        -0.0057,  0.0021,  0.0057, -0.0070,  0.0008,  0.0023, -0.0019,  0.0018,\n",
      "        -0.0074, -0.0103, -0.0136,  0.0033,  0.0012,  0.0030, -0.0012,  0.0024],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with open('data_home_assignment_2\\shakespeare-caesar.txt', encoding='latin-1') as f:\n",
    "    Text = f.read()\n",
    "w2i, text = word2indexMapping(Text)    \n",
    "# Test = 'Test for this assighment, it works for a smaller textfile!'\n",
    "# w2i, text = word2indexMapping(Test)\n",
    "X_ij = co_occurrenceFreq(text, w2i, k = 5)\n",
    "model = Glove(text, dimension=200)\n",
    "print('Original result.....')\n",
    "print(model.w_1, model.w_2, model.b_1, model.b_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings with gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim is a package which allows you to train word embeddings as well. The task is to take a text file (like 'shakespeare-caesar.txt') and generate embeddings of the vocabulary. You can consult the documentation here - \n",
    "https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'of': <gensim.models.keyedvectors.Vocab at 0x1ba88c8cf08>,\n",
       " 'caesar': <gensim.models.keyedvectors.Vocab at 0x1ba86451288>,\n",
       " 'by': <gensim.models.keyedvectors.Vocab at 0x1ba864512c8>,\n",
       " 'actus': <gensim.models.keyedvectors.Vocab at 0x1ba86451308>,\n",
       " 'enter': <gensim.models.keyedvectors.Vocab at 0x1ba86451848>,\n",
       " 'and': <gensim.models.keyedvectors.Vocab at 0x1ba864518c8>,\n",
       " 'ouer': <gensim.models.keyedvectors.Vocab at 0x1ba86451908>,\n",
       " 'the': <gensim.models.keyedvectors.Vocab at 0x1ba86451948>,\n",
       " 'home': <gensim.models.keyedvectors.Vocab at 0x1ba86451348>,\n",
       " 'you': <gensim.models.keyedvectors.Vocab at 0x1ba86451888>,\n",
       " 'get': <gensim.models.keyedvectors.Vocab at 0x1ba86451988>,\n",
       " 'is': <gensim.models.keyedvectors.Vocab at 0x1ba864519c8>,\n",
       " 'this': <gensim.models.keyedvectors.Vocab at 0x1ba86451a08>,\n",
       " 'a': <gensim.models.keyedvectors.Vocab at 0x1ba86451a48>,\n",
       " 'what,': <gensim.models.keyedvectors.Vocab at 0x1ba86451a88>,\n",
       " 'know': <gensim.models.keyedvectors.Vocab at 0x1ba86451ac8>,\n",
       " 'not': <gensim.models.keyedvectors.Vocab at 0x1ba86451b08>,\n",
       " 'walke': <gensim.models.keyedvectors.Vocab at 0x1ba86451b48>,\n",
       " 'vpon': <gensim.models.keyedvectors.Vocab at 0x1ba86451b88>,\n",
       " 'day,': <gensim.models.keyedvectors.Vocab at 0x1ba86451bc8>,\n",
       " 'without': <gensim.models.keyedvectors.Vocab at 0x1ba86451c08>,\n",
       " 'your': <gensim.models.keyedvectors.Vocab at 0x1ba86451c48>,\n",
       " 'speake,': <gensim.models.keyedvectors.Vocab at 0x1ba86451c88>,\n",
       " 'what': <gensim.models.keyedvectors.Vocab at 0x1ba86451cc8>,\n",
       " 'trade': <gensim.models.keyedvectors.Vocab at 0x1ba86451d08>,\n",
       " 'art': <gensim.models.keyedvectors.Vocab at 0x1ba86451d48>,\n",
       " 'why': <gensim.models.keyedvectors.Vocab at 0x1ba86451d88>,\n",
       " 'sir,': <gensim.models.keyedvectors.Vocab at 0x1ba86451dc8>,\n",
       " 'mur.': <gensim.models.keyedvectors.Vocab at 0x1ba86451e08>,\n",
       " 'where': <gensim.models.keyedvectors.Vocab at 0x1ba86451e48>,\n",
       " 'thy': <gensim.models.keyedvectors.Vocab at 0x1ba86451e88>,\n",
       " 'thou': <gensim.models.keyedvectors.Vocab at 0x1ba86451ec8>,\n",
       " 'with': <gensim.models.keyedvectors.Vocab at 0x1ba86451f08>,\n",
       " 'best': <gensim.models.keyedvectors.Vocab at 0x1ba86451f48>,\n",
       " 'are': <gensim.models.keyedvectors.Vocab at 0x1ba86451f88>,\n",
       " 'you?': <gensim.models.keyedvectors.Vocab at 0x1ba86451fc8>,\n",
       " 'in': <gensim.models.keyedvectors.Vocab at 0x1ba86452048>,\n",
       " 'respect': <gensim.models.keyedvectors.Vocab at 0x1ba86452088>,\n",
       " 'i': <gensim.models.keyedvectors.Vocab at 0x1ba864520c8>,\n",
       " 'am': <gensim.models.keyedvectors.Vocab at 0x1ba86452108>,\n",
       " 'but': <gensim.models.keyedvectors.Vocab at 0x1ba86452148>,\n",
       " 'as': <gensim.models.keyedvectors.Vocab at 0x1ba86452188>,\n",
       " 'would': <gensim.models.keyedvectors.Vocab at 0x1ba864521c8>,\n",
       " 'say,': <gensim.models.keyedvectors.Vocab at 0x1ba86452208>,\n",
       " 'answer': <gensim.models.keyedvectors.Vocab at 0x1ba86452248>,\n",
       " 'me': <gensim.models.keyedvectors.Vocab at 0x1ba86452288>,\n",
       " 'directly': <gensim.models.keyedvectors.Vocab at 0x1ba864522c8>,\n",
       " 'that': <gensim.models.keyedvectors.Vocab at 0x1ba86452308>,\n",
       " 'may': <gensim.models.keyedvectors.Vocab at 0x1ba86452348>,\n",
       " 'vse,': <gensim.models.keyedvectors.Vocab at 0x1ba86452388>,\n",
       " 'which': <gensim.models.keyedvectors.Vocab at 0x1ba864523c8>,\n",
       " 'bad': <gensim.models.keyedvectors.Vocab at 0x1ba86452408>,\n",
       " 'fla.': <gensim.models.keyedvectors.Vocab at 0x1ba86452448>,\n",
       " 'be': <gensim.models.keyedvectors.Vocab at 0x1ba86452488>,\n",
       " 'out': <gensim.models.keyedvectors.Vocab at 0x1ba864524c8>,\n",
       " 'me:': <gensim.models.keyedvectors.Vocab at 0x1ba86452508>,\n",
       " 'yet': <gensim.models.keyedvectors.Vocab at 0x1ba86452548>,\n",
       " 'if': <gensim.models.keyedvectors.Vocab at 0x1ba86452588>,\n",
       " 'can': <gensim.models.keyedvectors.Vocab at 0x1ba864525c8>,\n",
       " 'all': <gensim.models.keyedvectors.Vocab at 0x1ba86452608>,\n",
       " 'liue': <gensim.models.keyedvectors.Vocab at 0x1ba86452648>,\n",
       " 'by,': <gensim.models.keyedvectors.Vocab at 0x1ba86452688>,\n",
       " 'no': <gensim.models.keyedvectors.Vocab at 0x1ba864526c8>,\n",
       " 'nor': <gensim.models.keyedvectors.Vocab at 0x1ba86452708>,\n",
       " 'to': <gensim.models.keyedvectors.Vocab at 0x1ba86452748>,\n",
       " 'old': <gensim.models.keyedvectors.Vocab at 0x1ba86452788>,\n",
       " 'when': <gensim.models.keyedvectors.Vocab at 0x1ba864527c8>,\n",
       " 'they': <gensim.models.keyedvectors.Vocab at 0x1ba86452808>,\n",
       " 'great': <gensim.models.keyedvectors.Vocab at 0x1ba86452848>,\n",
       " 'them.': <gensim.models.keyedvectors.Vocab at 0x1ba86452888>,\n",
       " 'men': <gensim.models.keyedvectors.Vocab at 0x1ba864528c8>,\n",
       " 'euer': <gensim.models.keyedvectors.Vocab at 0x1ba86452908>,\n",
       " 'haue': <gensim.models.keyedvectors.Vocab at 0x1ba86452948>,\n",
       " 'my': <gensim.models.keyedvectors.Vocab at 0x1ba86452988>,\n",
       " 'wherefore': <gensim.models.keyedvectors.Vocab at 0x1ba864529c8>,\n",
       " 'leade': <gensim.models.keyedvectors.Vocab at 0x1ba86452a08>,\n",
       " 'these': <gensim.models.keyedvectors.Vocab at 0x1ba86452a48>,\n",
       " 'about': <gensim.models.keyedvectors.Vocab at 0x1ba86452a88>,\n",
       " 'their': <gensim.models.keyedvectors.Vocab at 0x1ba86452ac8>,\n",
       " 'selfe': <gensim.models.keyedvectors.Vocab at 0x1ba86452b08>,\n",
       " 'into': <gensim.models.keyedvectors.Vocab at 0x1ba86452b48>,\n",
       " 'more': <gensim.models.keyedvectors.Vocab at 0x1ba86452b88>,\n",
       " 'we': <gensim.models.keyedvectors.Vocab at 0x1ba86452bc8>,\n",
       " 'make': <gensim.models.keyedvectors.Vocab at 0x1ba86452c08>,\n",
       " 'see': <gensim.models.keyedvectors.Vocab at 0x1ba86452c48>,\n",
       " 'caesar,': <gensim.models.keyedvectors.Vocab at 0x1ba86452c88>,\n",
       " 'his': <gensim.models.keyedvectors.Vocab at 0x1ba86452cc8>,\n",
       " 'he': <gensim.models.keyedvectors.Vocab at 0x1ba86452d08>,\n",
       " 'follow': <gensim.models.keyedvectors.Vocab at 0x1ba86452d48>,\n",
       " 'him': <gensim.models.keyedvectors.Vocab at 0x1ba86452d88>,\n",
       " 'rome,': <gensim.models.keyedvectors.Vocab at 0x1ba86452dc8>,\n",
       " 'then': <gensim.models.keyedvectors.Vocab at 0x1ba86452e08>,\n",
       " 'o': <gensim.models.keyedvectors.Vocab at 0x1ba86452e48>,\n",
       " 'many': <gensim.models.keyedvectors.Vocab at 0x1ba86452e88>,\n",
       " 'time': <gensim.models.keyedvectors.Vocab at 0x1ba86452ec8>,\n",
       " 'vp': <gensim.models.keyedvectors.Vocab at 0x1ba86452f08>,\n",
       " 'there': <gensim.models.keyedvectors.Vocab at 0x1ba86452f48>,\n",
       " 'passe': <gensim.models.keyedvectors.Vocab at 0x1ba86452f88>,\n",
       " 'saw': <gensim.models.keyedvectors.Vocab at 0x1ba86452fc8>,\n",
       " 'made': <gensim.models.keyedvectors.Vocab at 0x1ba86455048>,\n",
       " 'an': <gensim.models.keyedvectors.Vocab at 0x1ba86455088>,\n",
       " 'her': <gensim.models.keyedvectors.Vocab at 0x1ba864550c8>,\n",
       " 'heare': <gensim.models.keyedvectors.Vocab at 0x1ba86455108>,\n",
       " 'do': <gensim.models.keyedvectors.Vocab at 0x1ba86455148>,\n",
       " 'now': <gensim.models.keyedvectors.Vocab at 0x1ba86455188>,\n",
       " 'put': <gensim.models.keyedvectors.Vocab at 0x1ba864551c8>,\n",
       " 'on': <gensim.models.keyedvectors.Vocab at 0x1ba86455208>,\n",
       " 'comes': <gensim.models.keyedvectors.Vocab at 0x1ba86455248>,\n",
       " 'pompeyes': <gensim.models.keyedvectors.Vocab at 0x1ba86455288>,\n",
       " 'fall': <gensim.models.keyedvectors.Vocab at 0x1ba864552c8>,\n",
       " 'pray': <gensim.models.keyedvectors.Vocab at 0x1ba86455308>,\n",
       " 'gods': <gensim.models.keyedvectors.Vocab at 0x1ba86455348>,\n",
       " 'must': <gensim.models.keyedvectors.Vocab at 0x1ba86455388>,\n",
       " 'good': <gensim.models.keyedvectors.Vocab at 0x1ba864553c8>,\n",
       " 'countrymen,': <gensim.models.keyedvectors.Vocab at 0x1ba86455408>,\n",
       " 'for': <gensim.models.keyedvectors.Vocab at 0x1ba86455448>,\n",
       " 'poore': <gensim.models.keyedvectors.Vocab at 0x1ba86455488>,\n",
       " 'them': <gensim.models.keyedvectors.Vocab at 0x1ba864554c8>,\n",
       " 'till': <gensim.models.keyedvectors.Vocab at 0x1ba86455508>,\n",
       " 'most': <gensim.models.keyedvectors.Vocab at 0x1ba86455548>,\n",
       " 'all.': <gensim.models.keyedvectors.Vocab at 0x1ba86455588>,\n",
       " 'exeunt.': <gensim.models.keyedvectors.Vocab at 0x1ba864555c8>,\n",
       " 'go': <gensim.models.keyedvectors.Vocab at 0x1ba86455608>,\n",
       " 'downe': <gensim.models.keyedvectors.Vocab at 0x1ba86455648>,\n",
       " 'way': <gensim.models.keyedvectors.Vocab at 0x1ba86455688>,\n",
       " 'will': <gensim.models.keyedvectors.Vocab at 0x1ba864556c8>,\n",
       " 'finde': <gensim.models.keyedvectors.Vocab at 0x1ba86455708>,\n",
       " 'so?': <gensim.models.keyedvectors.Vocab at 0x1ba86455748>,\n",
       " 'it': <gensim.models.keyedvectors.Vocab at 0x1ba86455788>,\n",
       " 'matter,': <gensim.models.keyedvectors.Vocab at 0x1ba864557c8>,\n",
       " 'let': <gensim.models.keyedvectors.Vocab at 0x1ba86455808>,\n",
       " 'caesars': <gensim.models.keyedvectors.Vocab at 0x1ba86455848>,\n",
       " 'ile': <gensim.models.keyedvectors.Vocab at 0x1ba86455888>,\n",
       " 'away': <gensim.models.keyedvectors.Vocab at 0x1ba864558c8>,\n",
       " 'from': <gensim.models.keyedvectors.Vocab at 0x1ba86455908>,\n",
       " 'so': <gensim.models.keyedvectors.Vocab at 0x1ba86455948>,\n",
       " 'perceiue': <gensim.models.keyedvectors.Vocab at 0x1ba86455988>,\n",
       " 'flye': <gensim.models.keyedvectors.Vocab at 0x1ba864559c8>,\n",
       " 'who': <gensim.models.keyedvectors.Vocab at 0x1ba86455a08>,\n",
       " 'else': <gensim.models.keyedvectors.Vocab at 0x1ba86455a48>,\n",
       " 'men,': <gensim.models.keyedvectors.Vocab at 0x1ba86455a88>,\n",
       " 'keepe': <gensim.models.keyedvectors.Vocab at 0x1ba86455ac8>,\n",
       " 'vs': <gensim.models.keyedvectors.Vocab at 0x1ba86455b08>,\n",
       " 'antony': <gensim.models.keyedvectors.Vocab at 0x1ba86455b48>,\n",
       " 'brutus,': <gensim.models.keyedvectors.Vocab at 0x1ba86455b88>,\n",
       " 'cassius,': <gensim.models.keyedvectors.Vocab at 0x1ba86455bc8>,\n",
       " 'caska,': <gensim.models.keyedvectors.Vocab at 0x1ba86455c08>,\n",
       " 'after': <gensim.models.keyedvectors.Vocab at 0x1ba86455c48>,\n",
       " 'caes.': <gensim.models.keyedvectors.Vocab at 0x1ba86455c88>,\n",
       " 'cask.': <gensim.models.keyedvectors.Vocab at 0x1ba86455cc8>,\n",
       " 'peace': <gensim.models.keyedvectors.Vocab at 0x1ba86455d08>,\n",
       " 'ho,': <gensim.models.keyedvectors.Vocab at 0x1ba86455d48>,\n",
       " 'speakes': <gensim.models.keyedvectors.Vocab at 0x1ba86455d88>,\n",
       " 'calp.': <gensim.models.keyedvectors.Vocab at 0x1ba86455dc8>,\n",
       " 'heere': <gensim.models.keyedvectors.Vocab at 0x1ba86455e08>,\n",
       " 'lord': <gensim.models.keyedvectors.Vocab at 0x1ba86455e48>,\n",
       " 'stand': <gensim.models.keyedvectors.Vocab at 0x1ba86455e88>,\n",
       " 'doth': <gensim.models.keyedvectors.Vocab at 0x1ba86455ec8>,\n",
       " 'run': <gensim.models.keyedvectors.Vocab at 0x1ba86455f08>,\n",
       " 'ant.': <gensim.models.keyedvectors.Vocab at 0x1ba86455f48>,\n",
       " 'our': <gensim.models.keyedvectors.Vocab at 0x1ba86455f88>,\n",
       " 'shake': <gensim.models.keyedvectors.Vocab at 0x1ba86455fc8>,\n",
       " 'off': <gensim.models.keyedvectors.Vocab at 0x1ba86459048>,\n",
       " 'shall': <gensim.models.keyedvectors.Vocab at 0x1ba86459088>,\n",
       " 'sayes,': <gensim.models.keyedvectors.Vocab at 0x1ba864590c8>,\n",
       " 'set': <gensim.models.keyedvectors.Vocab at 0x1ba86459108>,\n",
       " 'on,': <gensim.models.keyedvectors.Vocab at 0x1ba86459148>,\n",
       " 'leaue': <gensim.models.keyedvectors.Vocab at 0x1ba86459188>,\n",
       " 'sooth.': <gensim.models.keyedvectors.Vocab at 0x1ba864591c8>,\n",
       " 'bid': <gensim.models.keyedvectors.Vocab at 0x1ba86459208>,\n",
       " 'euery': <gensim.models.keyedvectors.Vocab at 0x1ba86459248>,\n",
       " 'me?': <gensim.models.keyedvectors.Vocab at 0x1ba86459288>,\n",
       " 'tongue': <gensim.models.keyedvectors.Vocab at 0x1ba864592c8>,\n",
       " 'caesar:': <gensim.models.keyedvectors.Vocab at 0x1ba86459308>,\n",
       " 'ides': <gensim.models.keyedvectors.Vocab at 0x1ba86459348>,\n",
       " 'march': <gensim.models.keyedvectors.Vocab at 0x1ba86459388>,\n",
       " 'man': <gensim.models.keyedvectors.Vocab at 0x1ba864593c8>,\n",
       " 'before': <gensim.models.keyedvectors.Vocab at 0x1ba86459408>,\n",
       " 'me,': <gensim.models.keyedvectors.Vocab at 0x1ba86459448>,\n",
       " 'face': <gensim.models.keyedvectors.Vocab at 0x1ba86459488>,\n",
       " 'cassi.': <gensim.models.keyedvectors.Vocab at 0x1ba864594c8>,\n",
       " 'fellow,': <gensim.models.keyedvectors.Vocab at 0x1ba86459508>,\n",
       " 'come': <gensim.models.keyedvectors.Vocab at 0x1ba86459548>,\n",
       " 'againe,': <gensim.models.keyedvectors.Vocab at 0x1ba86459588>,\n",
       " 'him:': <gensim.models.keyedvectors.Vocab at 0x1ba864595c8>,\n",
       " 'brut.': <gensim.models.keyedvectors.Vocab at 0x1ba86459608>,\n",
       " '&': <gensim.models.keyedvectors.Vocab at 0x1ba86459648>,\n",
       " 'cass.': <gensim.models.keyedvectors.Vocab at 0x1ba86459688>,\n",
       " 'some': <gensim.models.keyedvectors.Vocab at 0x1ba864596c8>,\n",
       " 'part': <gensim.models.keyedvectors.Vocab at 0x1ba86459708>,\n",
       " 'spirit': <gensim.models.keyedvectors.Vocab at 0x1ba86459748>,\n",
       " 'antony:': <gensim.models.keyedvectors.Vocab at 0x1ba86459788>,\n",
       " 'cassius': <gensim.models.keyedvectors.Vocab at 0x1ba864597c8>,\n",
       " 'eyes,': <gensim.models.keyedvectors.Vocab at 0x1ba86459808>,\n",
       " 'shew': <gensim.models.keyedvectors.Vocab at 0x1ba86459848>,\n",
       " 'loue,': <gensim.models.keyedvectors.Vocab at 0x1ba86459888>,\n",
       " 'was': <gensim.models.keyedvectors.Vocab at 0x1ba864598c8>,\n",
       " 'beare': <gensim.models.keyedvectors.Vocab at 0x1ba86459908>,\n",
       " 'too': <gensim.models.keyedvectors.Vocab at 0x1ba86459948>,\n",
       " 'strange': <gensim.models.keyedvectors.Vocab at 0x1ba86459988>,\n",
       " 'hand': <gensim.models.keyedvectors.Vocab at 0x1ba864599c8>,\n",
       " 'friend,': <gensim.models.keyedvectors.Vocab at 0x1ba86459a08>,\n",
       " 'loues': <gensim.models.keyedvectors.Vocab at 0x1ba86459a48>,\n",
       " 'bru.': <gensim.models.keyedvectors.Vocab at 0x1ba86459a88>,\n",
       " 'looke,': <gensim.models.keyedvectors.Vocab at 0x1ba86459ac8>,\n",
       " 'turne': <gensim.models.keyedvectors.Vocab at 0x1ba86459b08>,\n",
       " 'onely': <gensim.models.keyedvectors.Vocab at 0x1ba86459b48>,\n",
       " 'selfe,': <gensim.models.keyedvectors.Vocab at 0x1ba86459b88>,\n",
       " 'giue': <gensim.models.keyedvectors.Vocab at 0x1ba86459bc8>,\n",
       " 'therefore': <gensim.models.keyedvectors.Vocab at 0x1ba86459c08>,\n",
       " 'friends': <gensim.models.keyedvectors.Vocab at 0x1ba86459c48>,\n",
       " 'any': <gensim.models.keyedvectors.Vocab at 0x1ba86459c88>,\n",
       " 'further': <gensim.models.keyedvectors.Vocab at 0x1ba86459cc8>,\n",
       " 'brutus': <gensim.models.keyedvectors.Vocab at 0x1ba86459d08>,\n",
       " 'himselfe': <gensim.models.keyedvectors.Vocab at 0x1ba86459d48>,\n",
       " 'at': <gensim.models.keyedvectors.Vocab at 0x1ba86459d88>,\n",
       " 'loue': <gensim.models.keyedvectors.Vocab at 0x1ba86459dc8>,\n",
       " 'other': <gensim.models.keyedvectors.Vocab at 0x1ba86459e08>,\n",
       " 'much': <gensim.models.keyedvectors.Vocab at 0x1ba86459e48>,\n",
       " 'meanes': <gensim.models.keyedvectors.Vocab at 0x1ba86459e88>,\n",
       " 'mine': <gensim.models.keyedvectors.Vocab at 0x1ba86459ec8>,\n",
       " 'hath': <gensim.models.keyedvectors.Vocab at 0x1ba86459f08>,\n",
       " 'worthy': <gensim.models.keyedvectors.Vocab at 0x1ba86459f48>,\n",
       " 'tell': <gensim.models.keyedvectors.Vocab at 0x1ba86459f88>,\n",
       " 'brutus.': <gensim.models.keyedvectors.Vocab at 0x1ba86459fc8>,\n",
       " 'cassius:': <gensim.models.keyedvectors.Vocab at 0x1ba8645b048>,\n",
       " 'things': <gensim.models.keyedvectors.Vocab at 0x1ba8645b088>,\n",
       " 'cassius.': <gensim.models.keyedvectors.Vocab at 0x1ba8645b0c8>,\n",
       " \"'tis\": <gensim.models.keyedvectors.Vocab at 0x1ba8645b108>,\n",
       " 'very': <gensim.models.keyedvectors.Vocab at 0x1ba8645b148>,\n",
       " 'such': <gensim.models.keyedvectors.Vocab at 0x1ba8645b188>,\n",
       " 'might': <gensim.models.keyedvectors.Vocab at 0x1ba8645b1c8>,\n",
       " 'noble': <gensim.models.keyedvectors.Vocab at 0x1ba8645b208>,\n",
       " 'had': <gensim.models.keyedvectors.Vocab at 0x1ba8645b248>,\n",
       " 'eyes': <gensim.models.keyedvectors.Vocab at 0x1ba8645b288>,\n",
       " 'seeke': <gensim.models.keyedvectors.Vocab at 0x1ba8645b2c8>,\n",
       " 'cas.': <gensim.models.keyedvectors.Vocab at 0x1ba8645b308>,\n",
       " 'since': <gensim.models.keyedvectors.Vocab at 0x1ba8645b348>,\n",
       " 'know,': <gensim.models.keyedvectors.Vocab at 0x1ba8645b388>,\n",
       " 'cannot': <gensim.models.keyedvectors.Vocab at 0x1ba8645b3c8>,\n",
       " 'well': <gensim.models.keyedvectors.Vocab at 0x1ba8645b408>,\n",
       " 'gentle': <gensim.models.keyedvectors.Vocab at 0x1ba8645b448>,\n",
       " 'were': <gensim.models.keyedvectors.Vocab at 0x1ba8645b488>,\n",
       " 'common': <gensim.models.keyedvectors.Vocab at 0x1ba8645b4c8>,\n",
       " 'or': <gensim.models.keyedvectors.Vocab at 0x1ba8645b508>,\n",
       " 'did': <gensim.models.keyedvectors.Vocab at 0x1ba8645b548>,\n",
       " 'vse': <gensim.models.keyedvectors.Vocab at 0x1ba8645b588>,\n",
       " 'hold': <gensim.models.keyedvectors.Vocab at 0x1ba8645b5c8>,\n",
       " 'feare,': <gensim.models.keyedvectors.Vocab at 0x1ba8645b608>,\n",
       " 'people': <gensim.models.keyedvectors.Vocab at 0x1ba8645b648>,\n",
       " 'i,': <gensim.models.keyedvectors.Vocab at 0x1ba8645b688>,\n",
       " 'feare': <gensim.models.keyedvectors.Vocab at 0x1ba8645b6c8>,\n",
       " 'thinke': <gensim.models.keyedvectors.Vocab at 0x1ba8645b708>,\n",
       " 'it,': <gensim.models.keyedvectors.Vocab at 0x1ba8645b748>,\n",
       " 'generall': <gensim.models.keyedvectors.Vocab at 0x1ba8645b788>,\n",
       " 'honor': <gensim.models.keyedvectors.Vocab at 0x1ba8645b7c8>,\n",
       " 'one': <gensim.models.keyedvectors.Vocab at 0x1ba8645b808>,\n",
       " 'death': <gensim.models.keyedvectors.Vocab at 0x1ba8645b848>,\n",
       " 'looke': <gensim.models.keyedvectors.Vocab at 0x1ba8645b888>,\n",
       " 'both': <gensim.models.keyedvectors.Vocab at 0x1ba8645b8c8>,\n",
       " 'name': <gensim.models.keyedvectors.Vocab at 0x1ba8645b908>,\n",
       " 'well,': <gensim.models.keyedvectors.Vocab at 0x1ba8645b948>,\n",
       " 'be,': <gensim.models.keyedvectors.Vocab at 0x1ba8645b988>,\n",
       " 'you,': <gensim.models.keyedvectors.Vocab at 0x1ba8645b9c8>,\n",
       " 'once,': <gensim.models.keyedvectors.Vocab at 0x1ba8645ba08>,\n",
       " 'angry': <gensim.models.keyedvectors.Vocab at 0x1ba8645ba48>,\n",
       " 'word,': <gensim.models.keyedvectors.Vocab at 0x1ba8645ba88>,\n",
       " 'hearts': <gensim.models.keyedvectors.Vocab at 0x1ba8645bac8>,\n",
       " 'ere': <gensim.models.keyedvectors.Vocab at 0x1ba8645bb08>,\n",
       " 'could': <gensim.models.keyedvectors.Vocab at 0x1ba8645bb48>,\n",
       " 'so,': <gensim.models.keyedvectors.Vocab at 0x1ba8645bb88>,\n",
       " 'man,': <gensim.models.keyedvectors.Vocab at 0x1ba8645bbc8>,\n",
       " 'him.': <gensim.models.keyedvectors.Vocab at 0x1ba8645bc08>,\n",
       " 'fit': <gensim.models.keyedvectors.Vocab at 0x1ba8645bc48>,\n",
       " 'him,': <gensim.models.keyedvectors.Vocab at 0x1ba8645bc88>,\n",
       " 'marke': <gensim.models.keyedvectors.Vocab at 0x1ba8645bcc8>,\n",
       " 'how': <gensim.models.keyedvectors.Vocab at 0x1ba8645bd08>,\n",
       " 'true,': <gensim.models.keyedvectors.Vocab at 0x1ba8645bd48>,\n",
       " 'same': <gensim.models.keyedvectors.Vocab at 0x1ba8645bd88>,\n",
       " 'whose': <gensim.models.keyedvectors.Vocab at 0x1ba8645bdc8>,\n",
       " 'world,': <gensim.models.keyedvectors.Vocab at 0x1ba8645be08>,\n",
       " 'romans': <gensim.models.keyedvectors.Vocab at 0x1ba8645be48>,\n",
       " 'titinius,': <gensim.models.keyedvectors.Vocab at 0x1ba8645be88>,\n",
       " 'sicke': <gensim.models.keyedvectors.Vocab at 0x1ba8645bec8>,\n",
       " 'ye': <gensim.models.keyedvectors.Vocab at 0x1ba8645bf08>,\n",
       " 'gods,': <gensim.models.keyedvectors.Vocab at 0x1ba8645bf48>,\n",
       " 'should': <gensim.models.keyedvectors.Vocab at 0x1ba8645bf88>,\n",
       " 'world': <gensim.models.keyedvectors.Vocab at 0x1ba8645bfc8>,\n",
       " 'like': <gensim.models.keyedvectors.Vocab at 0x1ba8645e048>,\n",
       " 'vnder': <gensim.models.keyedvectors.Vocab at 0x1ba8645e088>,\n",
       " 'selues': <gensim.models.keyedvectors.Vocab at 0x1ba8645e0c8>,\n",
       " 'yours': <gensim.models.keyedvectors.Vocab at 0x1ba8645e108>,\n",
       " 'them,': <gensim.models.keyedvectors.Vocab at 0x1ba8645e148>,\n",
       " 'caesar.': <gensim.models.keyedvectors.Vocab at 0x1ba8645e188>,\n",
       " 'hast': <gensim.models.keyedvectors.Vocab at 0x1ba8645e1c8>,\n",
       " 'went': <gensim.models.keyedvectors.Vocab at 0x1ba8645e208>,\n",
       " 'say': <gensim.models.keyedvectors.Vocab at 0x1ba8645e248>,\n",
       " 'rome': <gensim.models.keyedvectors.Vocab at 0x1ba8645e288>,\n",
       " 'indeed,': <gensim.models.keyedvectors.Vocab at 0x1ba8645e2c8>,\n",
       " 'man.': <gensim.models.keyedvectors.Vocab at 0x1ba8645e308>,\n",
       " 'heard': <gensim.models.keyedvectors.Vocab at 0x1ba8645e348>,\n",
       " 'nothing': <gensim.models.keyedvectors.Vocab at 0x1ba8645e388>,\n",
       " 'this,': <gensim.models.keyedvectors.Vocab at 0x1ba8645e3c8>,\n",
       " 'times': <gensim.models.keyedvectors.Vocab at 0x1ba8645e408>,\n",
       " 'meete': <gensim.models.keyedvectors.Vocab at 0x1ba8645e448>,\n",
       " 'high': <gensim.models.keyedvectors.Vocab at 0x1ba8645e488>,\n",
       " 'then,': <gensim.models.keyedvectors.Vocab at 0x1ba8645e4c8>,\n",
       " 'this:': <gensim.models.keyedvectors.Vocab at 0x1ba8645e508>,\n",
       " 'rather': <gensim.models.keyedvectors.Vocab at 0x1ba8645e548>,\n",
       " 'sonne': <gensim.models.keyedvectors.Vocab at 0x1ba8645e588>,\n",
       " 'weake': <gensim.models.keyedvectors.Vocab at 0x1ba8645e5c8>,\n",
       " 'words': <gensim.models.keyedvectors.Vocab at 0x1ba8645e608>,\n",
       " 'thus': <gensim.models.keyedvectors.Vocab at 0x1ba8645e648>,\n",
       " 'fire': <gensim.models.keyedvectors.Vocab at 0x1ba8645e688>,\n",
       " 'done,': <gensim.models.keyedvectors.Vocab at 0x1ba8645e6c8>,\n",
       " 'caska': <gensim.models.keyedvectors.Vocab at 0x1ba8645e708>,\n",
       " 'note': <gensim.models.keyedvectors.Vocab at 0x1ba8645e748>,\n",
       " 'day': <gensim.models.keyedvectors.Vocab at 0x1ba8645e788>,\n",
       " 'so:': <gensim.models.keyedvectors.Vocab at 0x1ba8645e7c8>,\n",
       " 'cicero': <gensim.models.keyedvectors.Vocab at 0x1ba8645e808>,\n",
       " 'lookes': <gensim.models.keyedvectors.Vocab at 0x1ba8645e848>,\n",
       " 'seene': <gensim.models.keyedvectors.Vocab at 0x1ba8645e888>,\n",
       " 'capitoll': <gensim.models.keyedvectors.Vocab at 0x1ba8645e8c8>,\n",
       " 'being': <gensim.models.keyedvectors.Vocab at 0x1ba8645e908>,\n",
       " 'caes': <gensim.models.keyedvectors.Vocab at 0x1ba8645e948>,\n",
       " 'sleepe': <gensim.models.keyedvectors.Vocab at 0x1ba8645e988>,\n",
       " 'dangerous': <gensim.models.keyedvectors.Vocab at 0x1ba8645e9c8>,\n",
       " 'not:': <gensim.models.keyedvectors.Vocab at 0x1ba8645ea08>,\n",
       " 'through': <gensim.models.keyedvectors.Vocab at 0x1ba8645ea48>,\n",
       " 'himselfe,': <gensim.models.keyedvectors.Vocab at 0x1ba8645ea88>,\n",
       " 'neuer': <gensim.models.keyedvectors.Vocab at 0x1ba8645eac8>,\n",
       " 'thee': <gensim.models.keyedvectors.Vocab at 0x1ba8645eb08>,\n",
       " 'right': <gensim.models.keyedvectors.Vocab at 0x1ba8645eb48>,\n",
       " 'hand,': <gensim.models.keyedvectors.Vocab at 0x1ba8645eb88>,\n",
       " 'speake': <gensim.models.keyedvectors.Vocab at 0x1ba8645ebc8>,\n",
       " 'not?': <gensim.models.keyedvectors.Vocab at 0x1ba8645ec08>,\n",
       " 'crowne': <gensim.models.keyedvectors.Vocab at 0x1ba8645ec48>,\n",
       " \"offer'd\": <gensim.models.keyedvectors.Vocab at 0x1ba8645ec88>,\n",
       " 'him;': <gensim.models.keyedvectors.Vocab at 0x1ba8645ecc8>,\n",
       " 'backe': <gensim.models.keyedvectors.Vocab at 0x1ba8645ed08>,\n",
       " 'fell': <gensim.models.keyedvectors.Vocab at 0x1ba8645ed48>,\n",
       " 'last': <gensim.models.keyedvectors.Vocab at 0x1ba8645ed88>,\n",
       " 'cry': <gensim.models.keyedvectors.Vocab at 0x1ba8645edc8>,\n",
       " 'hee': <gensim.models.keyedvectors.Vocab at 0x1ba8645ee08>,\n",
       " 'it:': <gensim.models.keyedvectors.Vocab at 0x1ba8645ee48>,\n",
       " 'it.': <gensim.models.keyedvectors.Vocab at 0x1ba8645ee88>,\n",
       " 'that,': <gensim.models.keyedvectors.Vocab at 0x1ba8645eec8>,\n",
       " 'still': <gensim.models.keyedvectors.Vocab at 0x1ba8645ef08>,\n",
       " 'hands,': <gensim.models.keyedvectors.Vocab at 0x1ba8645ef48>,\n",
       " 'owne': <gensim.models.keyedvectors.Vocab at 0x1ba8645ef88>,\n",
       " 'part,': <gensim.models.keyedvectors.Vocab at 0x1ba8645efc8>,\n",
       " 'durst': <gensim.models.keyedvectors.Vocab at 0x1ba86463048>,\n",
       " 'you:': <gensim.models.keyedvectors.Vocab at 0x1ba86463088>,\n",
       " 'no,': <gensim.models.keyedvectors.Vocab at 0x1ba864630c8>,\n",
       " 'meane': <gensim.models.keyedvectors.Vocab at 0x1ba86463108>,\n",
       " 'sure': <gensim.models.keyedvectors.Vocab at 0x1ba86463148>,\n",
       " 'doe': <gensim.models.keyedvectors.Vocab at 0x1ba86463188>,\n",
       " 'true': <gensim.models.keyedvectors.Vocab at 0x1ba864631c8>,\n",
       " 'came': <gensim.models.keyedvectors.Vocab at 0x1ba86463208>,\n",
       " 'vnto': <gensim.models.keyedvectors.Vocab at 0x1ba86463248>,\n",
       " 'downe,': <gensim.models.keyedvectors.Vocab at 0x1ba86463288>,\n",
       " 'beene': <gensim.models.keyedvectors.Vocab at 0x1ba864632c8>,\n",
       " 'thing': <gensim.models.keyedvectors.Vocab at 0x1ba86463308>,\n",
       " 'three': <gensim.models.keyedvectors.Vocab at 0x1ba86463348>,\n",
       " \"there's\": <gensim.models.keyedvectors.Vocab at 0x1ba86463388>,\n",
       " 'done': <gensim.models.keyedvectors.Vocab at 0x1ba864633c8>,\n",
       " 'those': <gensim.models.keyedvectors.Vocab at 0x1ba86463408>,\n",
       " 'me.': <gensim.models.keyedvectors.Vocab at 0x1ba86463448>,\n",
       " 'fare': <gensim.models.keyedvectors.Vocab at 0x1ba86463488>,\n",
       " 'well.': <gensim.models.keyedvectors.Vocab at 0x1ba864634c8>,\n",
       " 'yet,': <gensim.models.keyedvectors.Vocab at 0x1ba86463508>,\n",
       " 'remember': <gensim.models.keyedvectors.Vocab at 0x1ba86463548>,\n",
       " 'night,': <gensim.models.keyedvectors.Vocab at 0x1ba86463588>,\n",
       " 'forth': <gensim.models.keyedvectors.Vocab at 0x1ba864635c8>,\n",
       " 'farewell': <gensim.models.keyedvectors.Vocab at 0x1ba86463608>,\n",
       " 'enter.': <gensim.models.keyedvectors.Vocab at 0x1ba86463648>,\n",
       " 'now,': <gensim.models.keyedvectors.Vocab at 0x1ba86463688>,\n",
       " 'better': <gensim.models.keyedvectors.Vocab at 0x1ba864636c8>,\n",
       " 'please': <gensim.models.keyedvectors.Vocab at 0x1ba86463708>,\n",
       " 'will,': <gensim.models.keyedvectors.Vocab at 0x1ba86463748>,\n",
       " 'exit': <gensim.models.keyedvectors.Vocab at 0x1ba86463788>,\n",
       " 'see,': <gensim.models.keyedvectors.Vocab at 0x1ba864637c8>,\n",
       " 'seuerall': <gensim.models.keyedvectors.Vocab at 0x1ba86463808>,\n",
       " 'dayes': <gensim.models.keyedvectors.Vocab at 0x1ba86463848>,\n",
       " 'brought': <gensim.models.keyedvectors.Vocab at 0x1ba86463888>,\n",
       " 'send': <gensim.models.keyedvectors.Vocab at 0x1ba864638c8>,\n",
       " 'left': <gensim.models.keyedvectors.Vocab at 0x1ba86463908>,\n",
       " 'fire,': <gensim.models.keyedvectors.Vocab at 0x1ba86463948>,\n",
       " 'sword,': <gensim.models.keyedvectors.Vocab at 0x1ba86463988>,\n",
       " 'against': <gensim.models.keyedvectors.Vocab at 0x1ba864639c8>,\n",
       " 'night': <gensim.models.keyedvectors.Vocab at 0x1ba86463a08>,\n",
       " 'euen': <gensim.models.keyedvectors.Vocab at 0x1ba86463a48>,\n",
       " 'word': <gensim.models.keyedvectors.Vocab at 0x1ba86463a88>,\n",
       " 'morrow': <gensim.models.keyedvectors.Vocab at 0x1ba86463ac8>,\n",
       " 'voyce': <gensim.models.keyedvectors.Vocab at 0x1ba86463b08>,\n",
       " 'this?': <gensim.models.keyedvectors.Vocab at 0x1ba86463b48>,\n",
       " 'full': <gensim.models.keyedvectors.Vocab at 0x1ba86463b88>,\n",
       " 'life,': <gensim.models.keyedvectors.Vocab at 0x1ba86463bc8>,\n",
       " 'cause,': <gensim.models.keyedvectors.Vocab at 0x1ba86463c08>,\n",
       " 'change': <gensim.models.keyedvectors.Vocab at 0x1ba86463c48>,\n",
       " 'spirits,': <gensim.models.keyedvectors.Vocab at 0x1ba86463c88>,\n",
       " 'not,': <gensim.models.keyedvectors.Vocab at 0x1ba86463cc8>,\n",
       " 'dead,': <gensim.models.keyedvectors.Vocab at 0x1ba86463d08>,\n",
       " 'here': <gensim.models.keyedvectors.Vocab at 0x1ba86463d48>,\n",
       " 'strong': <gensim.models.keyedvectors.Vocab at 0x1ba86463d88>,\n",
       " 'life': <gensim.models.keyedvectors.Vocab at 0x1ba86463dc8>,\n",
       " 'beares': <gensim.models.keyedvectors.Vocab at 0x1ba86463e08>,\n",
       " 'base': <gensim.models.keyedvectors.Vocab at 0x1ba86463e48>,\n",
       " 'vile': <gensim.models.keyedvectors.Vocab at 0x1ba86463e88>,\n",
       " 'stay': <gensim.models.keyedvectors.Vocab at 0x1ba86463ec8>,\n",
       " 'cinna.': <gensim.models.keyedvectors.Vocab at 0x1ba86463f08>,\n",
       " 'cinna,': <gensim.models.keyedvectors.Vocab at 0x1ba86463f48>,\n",
       " 'metellus': <gensim.models.keyedvectors.Vocab at 0x1ba86463f88>,\n",
       " 'two': <gensim.models.keyedvectors.Vocab at 0x1ba86463fc8>,\n",
       " 'take': <gensim.models.keyedvectors.Vocab at 0x1ba86466048>,\n",
       " 'vs.': <gensim.models.keyedvectors.Vocab at 0x1ba86466088>,\n",
       " 'decius': <gensim.models.keyedvectors.Vocab at 0x1ba864660c8>,\n",
       " 'trebonius': <gensim.models.keyedvectors.Vocab at 0x1ba86466108>,\n",
       " 'appeare': <gensim.models.keyedvectors.Vocab at 0x1ba86466148>,\n",
       " 'vs,': <gensim.models.keyedvectors.Vocab at 0x1ba86466188>,\n",
       " 'awake': <gensim.models.keyedvectors.Vocab at 0x1ba864661c8>,\n",
       " 'lucius,': <gensim.models.keyedvectors.Vocab at 0x1ba86466208>,\n",
       " 'lucius.': <gensim.models.keyedvectors.Vocab at 0x1ba86466248>,\n",
       " 'luc.': <gensim.models.keyedvectors.Vocab at 0x1ba86466288>,\n",
       " 'lord?': <gensim.models.keyedvectors.Vocab at 0x1ba864662c8>,\n",
       " 'call': <gensim.models.keyedvectors.Vocab at 0x1ba86466308>,\n",
       " 'is,': <gensim.models.keyedvectors.Vocab at 0x1ba86466348>,\n",
       " 'least': <gensim.models.keyedvectors.Vocab at 0x1ba86466388>,\n",
       " 'kill': <gensim.models.keyedvectors.Vocab at 0x1ba864663c8>,\n",
       " 'found': <gensim.models.keyedvectors.Vocab at 0x1ba86466408>,\n",
       " 'lye': <gensim.models.keyedvectors.Vocab at 0x1ba86466448>,\n",
       " 'day:': <gensim.models.keyedvectors.Vocab at 0x1ba86466488>,\n",
       " 'first': <gensim.models.keyedvectors.Vocab at 0x1ba864664c8>,\n",
       " 'bring': <gensim.models.keyedvectors.Vocab at 0x1ba86466508>,\n",
       " 'reade': <gensim.models.keyedvectors.Vocab at 0x1ba86466548>,\n",
       " 'tooke': <gensim.models.keyedvectors.Vocab at 0x1ba86466588>,\n",
       " 'body': <gensim.models.keyedvectors.Vocab at 0x1ba864665c8>,\n",
       " 'little': <gensim.models.keyedvectors.Vocab at 0x1ba86466608>,\n",
       " 'brother': <gensim.models.keyedvectors.Vocab at 0x1ba86466648>,\n",
       " 'wilt': <gensim.models.keyedvectors.Vocab at 0x1ba86466688>,\n",
       " 'none': <gensim.models.keyedvectors.Vocab at 0x1ba864666c8>,\n",
       " 'hide': <gensim.models.keyedvectors.Vocab at 0x1ba86466708>,\n",
       " 'night:': <gensim.models.keyedvectors.Vocab at 0x1ba86466748>,\n",
       " 'roman': <gensim.models.keyedvectors.Vocab at 0x1ba86466788>,\n",
       " 'you.': <gensim.models.keyedvectors.Vocab at 0x1ba864667c8>,\n",
       " 'welcome': <gensim.models.keyedvectors.Vocab at 0x1ba86466808>,\n",
       " 'cymber': <gensim.models.keyedvectors.Vocab at 0x1ba86466848>,\n",
       " 'decius.': <gensim.models.keyedvectors.Vocab at 0x1ba86466888>,\n",
       " 'breake': <gensim.models.keyedvectors.Vocab at 0x1ba864668c8>,\n",
       " 'heere?': <gensim.models.keyedvectors.Vocab at 0x1ba86466908>,\n",
       " 'cin.': <gensim.models.keyedvectors.Vocab at 0x1ba86466948>,\n",
       " 'heere,': <gensim.models.keyedvectors.Vocab at 0x1ba86466988>,\n",
       " 'hands': <gensim.models.keyedvectors.Vocab at 0x1ba864669c8>,\n",
       " 'cause': <gensim.models.keyedvectors.Vocab at 0x1ba86466a08>,\n",
       " 'romans,': <gensim.models.keyedvectors.Vocab at 0x1ba86466a48>,\n",
       " 'blood': <gensim.models.keyedvectors.Vocab at 0x1ba86466a88>,\n",
       " 'him?': <gensim.models.keyedvectors.Vocab at 0x1ba86466ac8>,\n",
       " 'antony,': <gensim.models.keyedvectors.Vocab at 0x1ba86466b08>,\n",
       " 'farre': <gensim.models.keyedvectors.Vocab at 0x1ba86466b48>,\n",
       " 'seeme': <gensim.models.keyedvectors.Vocab at 0x1ba86466b88>,\n",
       " 'caius': <gensim.models.keyedvectors.Vocab at 0x1ba86466bc8>,\n",
       " 'cut': <gensim.models.keyedvectors.Vocab at 0x1ba86466c08>,\n",
       " 'death,': <gensim.models.keyedvectors.Vocab at 0x1ba86466c48>,\n",
       " \"let's\": <gensim.models.keyedvectors.Vocab at 0x1ba86466c88>,\n",
       " 'friends,': <gensim.models.keyedvectors.Vocab at 0x1ba86466cc8>,\n",
       " 'stirre': <gensim.models.keyedvectors.Vocab at 0x1ba86466d08>,\n",
       " 'dye': <gensim.models.keyedvectors.Vocab at 0x1ba86466d48>,\n",
       " 'liue,': <gensim.models.keyedvectors.Vocab at 0x1ba86466d88>,\n",
       " 'peace,': <gensim.models.keyedvectors.Vocab at 0x1ba86466dc8>,\n",
       " 'whether': <gensim.models.keyedvectors.Vocab at 0x1ba86466e08>,\n",
       " 'fetch': <gensim.models.keyedvectors.Vocab at 0x1ba86466e48>,\n",
       " \"wee'l\": <gensim.models.keyedvectors.Vocab at 0x1ba86466e88>,\n",
       " 'por.': <gensim.models.keyedvectors.Vocab at 0x1ba86466ec8>,\n",
       " 'gaue': <gensim.models.keyedvectors.Vocab at 0x1ba86466f08>,\n",
       " 'lord,': <gensim.models.keyedvectors.Vocab at 0x1ba86466f48>,\n",
       " 'portia': <gensim.models.keyedvectors.Vocab at 0x1ba86466f88>,\n",
       " 'within': <gensim.models.keyedvectors.Vocab at 0x1ba86466fc8>,\n",
       " 'place': <gensim.models.keyedvectors.Vocab at 0x1ba86469048>,\n",
       " 'talke': <gensim.models.keyedvectors.Vocab at 0x1ba86469088>,\n",
       " 'honourable': <gensim.models.keyedvectors.Vocab at 0x1ba864690c8>,\n",
       " 'deere': <gensim.models.keyedvectors.Vocab at 0x1ba86469108>,\n",
       " 'heart': <gensim.models.keyedvectors.Vocab at 0x1ba86469148>,\n",
       " 'thee,': <gensim.models.keyedvectors.Vocab at 0x1ba86469188>,\n",
       " 'lucius': <gensim.models.keyedvectors.Vocab at 0x1ba864691c8>,\n",
       " 'ligarius,': <gensim.models.keyedvectors.Vocab at 0x1ba86469208>,\n",
       " 'boy,': <gensim.models.keyedvectors.Vocab at 0x1ba86469248>,\n",
       " 'cai.': <gensim.models.keyedvectors.Vocab at 0x1ba86469288>,\n",
       " 'braue': <gensim.models.keyedvectors.Vocab at 0x1ba864692c8>,\n",
       " 'seruant.': <gensim.models.keyedvectors.Vocab at 0x1ba86469308>,\n",
       " 'ser.': <gensim.models.keyedvectors.Vocab at 0x1ba86469348>,\n",
       " 'house': <gensim.models.keyedvectors.Vocab at 0x1ba86469388>,\n",
       " 'end': <gensim.models.keyedvectors.Vocab at 0x1ba864693c8>,\n",
       " 'mighty': <gensim.models.keyedvectors.Vocab at 0x1ba86469408>,\n",
       " 'come,': <gensim.models.keyedvectors.Vocab at 0x1ba86469448>,\n",
       " 'house,': <gensim.models.keyedvectors.Vocab at 0x1ba86469488>,\n",
       " 'mark': <gensim.models.keyedvectors.Vocab at 0x1ba864694c8>,\n",
       " 'deci.': <gensim.models.keyedvectors.Vocab at 0x1ba86469508>,\n",
       " 'she': <gensim.models.keyedvectors.Vocab at 0x1ba86469548>,\n",
       " 'pardon': <gensim.models.keyedvectors.Vocab at 0x1ba86469588>,\n",
       " 'publius': <gensim.models.keyedvectors.Vocab at 0x1ba864695c8>,\n",
       " 'prepare': <gensim.models.keyedvectors.Vocab at 0x1ba86469608>,\n",
       " 'blame': <gensim.models.keyedvectors.Vocab at 0x1ba86469648>,\n",
       " 'will:': <gensim.models.keyedvectors.Vocab at 0x1ba86469688>,\n",
       " 'thee.': <gensim.models.keyedvectors.Vocab at 0x1ba864696c8>,\n",
       " 'traitors': <gensim.models.keyedvectors.Vocab at 0x1ba86469708>,\n",
       " 'suite': <gensim.models.keyedvectors.Vocab at 0x1ba86469748>,\n",
       " 'read': <gensim.models.keyedvectors.Vocab at 0x1ba86469788>,\n",
       " 'friend': <gensim.models.keyedvectors.Vocab at 0x1ba864697c8>,\n",
       " 'master': <gensim.models.keyedvectors.Vocab at 0x1ba86469808>,\n",
       " \"lou'd\": <gensim.models.keyedvectors.Vocab at 0x1ba86469848>,\n",
       " 'dead': <gensim.models.keyedvectors.Vocab at 0x1ba86469888>,\n",
       " 'though': <gensim.models.keyedvectors.Vocab at 0x1ba864698c8>,\n",
       " 'bloody': <gensim.models.keyedvectors.Vocab at 0x1ba86469908>,\n",
       " 'wrong': <gensim.models.keyedvectors.Vocab at 0x1ba86469948>,\n",
       " 'marcus': <gensim.models.keyedvectors.Vocab at 0x1ba86469988>,\n",
       " \"did'st\": <gensim.models.keyedvectors.Vocab at 0x1ba864699c8>,\n",
       " 'so.': <gensim.models.keyedvectors.Vocab at 0x1ba86469a08>,\n",
       " 'octauius': <gensim.models.keyedvectors.Vocab at 0x1ba86469a48>,\n",
       " 'yong': <gensim.models.keyedvectors.Vocab at 0x1ba86469a88>,\n",
       " 'octauius,': <gensim.models.keyedvectors.Vocab at 0x1ba86469ac8>,\n",
       " '2.': <gensim.models.keyedvectors.Vocab at 0x1ba86469b08>,\n",
       " '3.': <gensim.models.keyedvectors.Vocab at 0x1ba86469b48>,\n",
       " '1.': <gensim.models.keyedvectors.Vocab at 0x1ba86469b88>,\n",
       " '4.': <gensim.models.keyedvectors.Vocab at 0x1ba86469bc8>,\n",
       " '1': <gensim.models.keyedvectors.Vocab at 0x1ba86469c08>,\n",
       " '3': <gensim.models.keyedvectors.Vocab at 0x1ba86469c48>,\n",
       " '4': <gensim.models.keyedvectors.Vocab at 0x1ba86469c88>,\n",
       " '2': <gensim.models.keyedvectors.Vocab at 0x1ba86469cc8>,\n",
       " 'heart,': <gensim.models.keyedvectors.Vocab at 0x1ba86469d08>,\n",
       " 'away,': <gensim.models.keyedvectors.Vocab at 0x1ba86469d48>,\n",
       " 'cinna': <gensim.models.keyedvectors.Vocab at 0x1ba86469d88>,\n",
       " 'octa.': <gensim.models.keyedvectors.Vocab at 0x1ba86469dc8>,\n",
       " 'meet': <gensim.models.keyedvectors.Vocab at 0x1ba86469e08>,\n",
       " 'lucillius,': <gensim.models.keyedvectors.Vocab at 0x1ba86469e48>,\n",
       " 'titinius': <gensim.models.keyedvectors.Vocab at 0x1ba86469e88>,\n",
       " 'pindarus': <gensim.models.keyedvectors.Vocab at 0x1ba86469ec8>,\n",
       " 'lucil.': <gensim.models.keyedvectors.Vocab at 0x1ba86469f08>,\n",
       " 'ill': <gensim.models.keyedvectors.Vocab at 0x1ba86469f48>,\n",
       " 'lucillius': <gensim.models.keyedvectors.Vocab at 0x1ba86469f88>,\n",
       " 'tent': <gensim.models.keyedvectors.Vocab at 0x1ba86469fc8>,\n",
       " 'messala': <gensim.models.keyedvectors.Vocab at 0x1ba8646c048>,\n",
       " 'messala,': <gensim.models.keyedvectors.Vocab at 0x1ba8646c088>,\n",
       " 'philippi': <gensim.models.keyedvectors.Vocab at 0x1ba8646c0c8>,\n",
       " 'messa.': <gensim.models.keyedvectors.Vocab at 0x1ba8646c108>,\n",
       " 'enemy': <gensim.models.keyedvectors.Vocab at 0x1ba8646c148>,\n",
       " 'tit.': <gensim.models.keyedvectors.Vocab at 0x1ba8646c188>,\n",
       " 'sword': <gensim.models.keyedvectors.Vocab at 0x1ba8646c1c8>,\n",
       " 'cato,': <gensim.models.keyedvectors.Vocab at 0x1ba8646c208>,\n",
       " 'alarum.': <gensim.models.keyedvectors.Vocab at 0x1ba8646c248>,\n",
       " 'titin.': <gensim.models.keyedvectors.Vocab at 0x1ba8646c288>,\n",
       " 'strato,': <gensim.models.keyedvectors.Vocab at 0x1ba8646c2c8>,\n",
       " 'clit.': <gensim.models.keyedvectors.Vocab at 0x1ba8646c308>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import gensim.models as gmodels\n",
    "\n",
    "\n",
    "# get sentece from the raw txt\n",
    "f = open('data_home_assignment_2\\shakespeare-caesar.txt')\n",
    "raw = f.read()\n",
    "sent_tokens = nltk.sent_tokenize(raw)\n",
    "\n",
    "#preprocessing the sentence: strip unnecesary data normalizing cases\n",
    "sentences=[]\n",
    "for sent in sent_tokens:\n",
    "    s = re.split(r'\\s+',sent.strip()) #using re to remove \\n\\n \\t and so on\n",
    "    sentence = [w.lower() for w in s] #normalizing cases\n",
    "    # print(string.punctuation)\n",
    "    sentences.append(sentence)\n",
    "    \n",
    "model = gmodels.Word2Vec(sentences=sentences)\n",
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word similarity with pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way of understanding how good the obtained embeddings are is the word similarity task. The file 'sim353.csv' contains a set of word pairs as well as their similarity as judged by humans (e.g., tiger,tiger,10). \n",
    "Also we provide a set of pre-trained embeddings in 'embeddings.pickle' in the form of a dictionary with words as keys and embeddings as values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Consider each word pair in the given file ('sim353.csv') and calculate the cosine similarity between them and then rank the word pairs based on the similarity value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Human (mean)</th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>rank (cos.sim.)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>money</td>\n",
       "      <td>cash</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.815317</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>money</td>\n",
       "      <td>cash</td>\n",
       "      <td>9.15</td>\n",
       "      <td>0.815317</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>football</td>\n",
       "      <td>soccer</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.814274</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>championship</td>\n",
       "      <td>tournament</td>\n",
       "      <td>8.36</td>\n",
       "      <td>0.807413</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>cup</td>\n",
       "      <td>entity</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.095603</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>professor</td>\n",
       "      <td>cucumber</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.088859</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>cup</td>\n",
       "      <td>artifact</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.045669</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>rooster</td>\n",
       "      <td>voyage</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.038883</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tiger</td>\n",
       "      <td>organism</td>\n",
       "      <td>4.77</td>\n",
       "      <td>0.036870</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 1      Word 2  Human (mean)   cos_sim  rank (cos.sim.)\n",
       "2           tiger       tiger         10.00  1.000000                1\n",
       "90          money        cash          9.08  0.815317                2\n",
       "30          money        cash          9.15  0.815317                3\n",
       "38       football      soccer          9.03  0.814274                4\n",
       "279  championship  tournament          8.36  0.807413                5\n",
       "..            ...         ...           ...       ...              ...\n",
       "138           cup      entity          2.15  0.095603              331\n",
       "31      professor    cucumber          0.31  0.088859              332\n",
       "136           cup    artifact          2.92  0.045669              333\n",
       "88        rooster      voyage          0.62  0.038883              334\n",
       "105         tiger    organism          4.77  0.036870              335\n",
       "\n",
       "[335 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "#read from pick and csv\n",
    "pickle_in = open('data_home_assignment_2\\embeddings.pickle','rb')\n",
    "embeddings = pickle.load(pickle_in)\n",
    "csv_in = pd.read_csv('data_home_assignment_2\\sim353.csv',delimiter=',')\n",
    "df_sim353 = pd.DataFrame(csv_in)\n",
    "\n",
    "word1 = df_sim353['Word 1']\n",
    "word2 = df_sim353['Word 2']\n",
    "sim_human = df_sim353['Human (mean)']\n",
    "pairlen = len(word1)\n",
    "\n",
    "# calculate the cosine similarity between word pair, \n",
    "# if a word not in the embedding, \n",
    "# the similarity will be replaced by the similarity measured by human \n",
    "words = embeddings.keys()\n",
    "cos_sim = []\n",
    "for i in range(pairlen):\n",
    "    if word1[i] in words and word2[i] in words:\n",
    "        a = embeddings[word1[i]]\n",
    "        b = embeddings[word2[i]]\n",
    "        # calculate cosin similarity\n",
    "        cos_sim.append(np.inner(a,b)/(norm(a)*norm(b)))\n",
    "    else:\n",
    "        cos_sim.append(sim_human[i]/10) #divid 10 to change it into value in [0,1]\n",
    "\n",
    "# add a cloumn cosine similarity sorted the table according to it\n",
    "df = df_sim353.copy(deep=True)\n",
    "df['cos_sim']= cos_sim\n",
    "df_cos_sorted = df.sort_values(by=['cos_sim'],ascending=False)\n",
    "rank = range(1,pairlen+1)\n",
    "df_cos_sorted['rank (cos.sim.)'] = rank\n",
    "display(df_cos_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Rank the word pairs based on the similarity values as determined by humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Human (mean)</th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>rank (human)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>fuck</td>\n",
       "      <td>sex</td>\n",
       "      <td>9.44</td>\n",
       "      <td>0.670561</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>midday</td>\n",
       "      <td>noon</td>\n",
       "      <td>9.29</td>\n",
       "      <td>0.665748</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>journey</td>\n",
       "      <td>voyage</td>\n",
       "      <td>9.29</td>\n",
       "      <td>0.643200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>dollar</td>\n",
       "      <td>buck</td>\n",
       "      <td>9.22</td>\n",
       "      <td>0.426276</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>rooster</td>\n",
       "      <td>voyage</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.038883</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>noon</td>\n",
       "      <td>string</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.122765</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>chord</td>\n",
       "      <td>smile</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.181856</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>professor</td>\n",
       "      <td>cucumber</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.088859</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>king</td>\n",
       "      <td>cabbage</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.182654</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word 1    Word 2  Human (mean)   cos_sim  rank (human)\n",
       "2        tiger     tiger         10.00  1.000000             1\n",
       "37        fuck       sex          9.44  0.670561             2\n",
       "66      midday      noon          9.29  0.665748             3\n",
       "61     journey    voyage          9.29  0.643200             4\n",
       "249     dollar      buck          9.22  0.426276             5\n",
       "..         ...       ...           ...       ...           ...\n",
       "88     rooster    voyage          0.62  0.038883           331\n",
       "87        noon    string          0.54  0.122765           332\n",
       "85       chord     smile          0.54  0.181856           333\n",
       "31   professor  cucumber          0.31  0.088859           334\n",
       "32        king   cabbage          0.23  0.182654           335\n",
       "\n",
       "[335 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_sorted = df.sort_values(by=['Human (mean)'],ascending=False)\n",
    "\n",
    "df_human_sorted['rank (human)'] = rank\n",
    "df_human_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Calculate the spearman rank correlation between the two ranked list of word-pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.6450611570036899, pvalue=8.391971318047088e-41)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# sorted this two lists according to index, each row represents the same word pair\n",
    "df_cos = df_cos_sorted.sort_index()\n",
    "df_human = df_human_sorted.sort_index()\n",
    "data1 = df_human['rank (human)']\n",
    "data2 = df_cos['rank (cos.sim.)']\n",
    "spearmanr(data1, data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification with CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a set of news articles which are to be labelled 1 or 0. The data is split into 3 groups (train/test/validation). Each group is further divided into 2 files which consists of the text(ending with \\_X.p) and the label (ending with \\_y.p) respectively. Each datapoint is a list of words and they are all accumulated in a list forming a list of lists. The label file is a list of labels (0/1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will design a character-level CNN. So the first task would be to obtain a one-hot encoding for the characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the vocabulary of caracters is provided for your reference.. \n",
    "vocabulary = list(\"\"\" abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'/\\|_@#$%ˆ&*˜‘+-=<>()[]{}\"\"\")\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '0': 27, '1': 28, '2': 29, '3': 30, '4': 31, '5': 32, '6': 33, '7': 34, '8': 35, '9': 36, '-': 59, ',': 38, ';': 39, '.': 40, '!': 41, '?': 42, ':': 43, \"'\": 44, '/': 45, '\\\\': 46, '|': 47, '_': 48, '@': 49, '#': 50, '$': 51, '%': 52, 'ˆ': 53, '&': 54, '*': 55, '˜': 56, '‘': 57, '+': 58, '=': 60, '<': 61, '>': 62, '(': 63, ')': 64, '[': 65, ']': 66, '{': 67, '}': 68}\n"
     ]
    }
   ],
   "source": [
    "def characterEncoding(vocabulary):\n",
    "    c2v = {} # dictionary with key as a character and one-hot encoding as value\n",
    "    # write your code snippet here..  \n",
    "    # dictionary that maps every char to an unique int based on position\n",
    "    c2v = dict((c,i) for i,c in enumerate(vocabulary))\n",
    "    return c2v\n",
    "#test\n",
    "c2v= characterEncoding(vocabulary)\n",
    "print(c2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode a sentence as a 2D matrix with each row representing the one-hot encoding of a character in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "def sentence2tensor(sentence,c2v):\n",
    "    # Here we assume that all characters in sentences are within the alphabet, we only count the the first 100 characters\n",
    "    # TODO\n",
    "    # input: sentence\n",
    "    # output: a 2D matrix with each row is a vector filled with 0 and 1, and value is where the 1 is.\n",
    "   \n",
    "    matrix = []\n",
    "    for c in sentence:\n",
    "        if c in c2v:\n",
    "            vector = (np.zeros((len(c2v)+1),dtype=object))\n",
    "            vector[c2v[c]] = 1\n",
    "            matrix.append(vector)\n",
    "\n",
    "    return torch.LongTensor(matrix)[0:100]\n",
    "\n",
    "#test\n",
    "#sentence2tensor(\"hello world\",c2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a dataset class for feeding data to your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['news_computer_test_X.p', 'news_computer_test_y.p', 'news_computer_train_X.p', 'news_computer_train_y.p', 'news_computer_val_X.p', 'news_computer_val_y.p']\n",
      "torch.Size([234, 1, 100, 69])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import fnmatch\n",
    "import torch\n",
    "\n",
    "ListOfFile = os.listdir('data_home_assignment_2/Data/')\n",
    "print(ListOfFile)\n",
    "################\n",
    "# ProcessingData function pre-process data to a list of 2D matrix.It accepts a list of list of words,\n",
    "# and then change each list of words into a 2D matrix by using sentence2tensor.Returned the first 100 character of each sentence\n",
    "# since we want to make sure that every matrix shape is the same.\n",
    "# ** Here we use tensor unsqueeze to add one dimension so that we can feed into the model, we add to second place and first place \n",
    "#  is 32, so that we have [32,1,100,69] were 100*69 is the size of matrix, and 32 is the batch size, which every loop there 32 matrices \n",
    "# feed into the model.\n",
    "#\n",
    "# Input: @file: String indicated \"train\",\"test\" or \"validation\" \n",
    "# Output: @tensor: tensor type list of 2D matrix\n",
    "#         @label: tensor type labels\n",
    "#################\n",
    "def ProcessingData(file):\n",
    "    filename = ''\n",
    "    pre = 'data_home_assignment_2/Data/'\n",
    "    if file == \"test\":\n",
    "        filename = pre+'news_computer_test_X.p'\n",
    "        labels = pre+'news_computer_test_y.p'\n",
    "    elif file == \"train\":\n",
    "        filename = pre+'news_computer_train_X.p'\n",
    "        labels = pre+'news_computer_train_y.p'\n",
    "    elif file == \"validation\":\n",
    "        filename = pre+'news_computer_val_X.p'\n",
    "        labels = pre+'news_computer_val_y.p'\n",
    "            \n",
    "    # use pickle to load infomation\n",
    "    context = pickle.load(open(filename,\"rb\"))\n",
    "    lst = []\n",
    "    for List in context:\n",
    "        sentence = ''\n",
    "        for word in List:\n",
    "            sentence+=word\n",
    "        #find the shortest sentence and truncate others to same length\n",
    "        l= sentence2tensor(sentence,c2v)\n",
    "        lst.append(l)\n",
    "    \n",
    "    label = torch.LongTensor(pickle.load(open(labels,\"rb\"))) \n",
    "    tensor = (torch.stack(lst)).unsqueeze(1)\n",
    "    return tensor.long(),label.long()\n",
    "\n",
    "a,n = ProcessingData('validation')\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "###############\n",
    "#Here we design a NewsDataset inherit Dataset, but most of the processing Data we did outside this function\n",
    "# \n",
    "##############\n",
    "class NewsDataset(Dataset): \n",
    "     def __init__(self, names, labels):\n",
    "        super(NewsDataset,self).__init__()\n",
    "        self.names = names\n",
    "        self.labels = labels\n",
    "    \n",
    "     def __len__(self):\n",
    "        return len(self.names)\n",
    "    \n",
    "     def __getitem__(self,index):\n",
    "        #self.names = Variable(np.random.rand(1,1,100,69))\n",
    "        #(self.names).unsqueeze(0)\n",
    "        self.names = Variable(self.names).type(torch.LongTensor)\n",
    "        self.labels = Variable(self.labels).type(torch.LongTensor)\n",
    "    \n",
    "        return self.names[index],self.labels[index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a model class with 2 layers of convolutions each followed by a ReLU unit. The model should have linear layer which maps to the classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        #self.sample_size = sample_size\n",
    "        # Defining two 2D convolution layers and followed by ReLU, and one fully connnected layer  \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(69*100*32, 32)\n",
    "  \n",
    "      \n",
    "  # define forward function\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "      \n",
    "        #flatten x to be one dimension \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a train function which trains on the train dataset. You can use binary cross entropy as your loss function and Adam as your optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "    \n",
    "def train(model, train_dataset, epochs=5, batch_size=32, learning_rate=0.0001):\n",
    "  \n",
    "    #We get data packed in batsch size by using dataloader\n",
    "    train_dataloader = DataLoader(train_dataset,32)\n",
    "    # loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(),lr= learning_rate)\n",
    "    for epoch in range(epochs):  \n",
    "        # loop over the dataset multiple times\n",
    "\n",
    "        for i, data in enumerate(train_dataloader,0):\n",
    "            inputs, labels = data\n",
    "            inputs= inputs.to(torch.float32)\n",
    "            labels = torch.LongTensor(labels)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a test function which takes the trained model and test dataset and outputs the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# test function calculate the accuracy by feeding data to model and get its predicted output  \n",
    "#########################\n",
    "def test(model, test_dataset, batch_size=32):\n",
    "    \n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            inputs, labels = data\n",
    "            inputs= inputs.to(torch.float32)\n",
    "            labels = torch.LongTensor(labels)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the testset: %d %%' % (100 * correct / total))\n",
    "    \n",
    "    # write your code snippet here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 100, 69])\n",
      "torch.Size([32, 1, 100, 69])\n",
      "torch.Size([32, 1, 100, 69])\n",
      "torch.Size([32, 1, 100, 69])\n",
      "torch.Size([32, 1, 100, 69])\n",
      "torch.Size([32, 1, 100, 69])\n",
      "torch.Size([32, 1, 100, 69])\n",
      "torch.Size([10, 1, 100, 69])\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "########### Test DataLoaderis working ######\n",
    "#################################################################\n",
    "import torch.optim as optim\n",
    "\n",
    "# Total has 234 for validation for batch size 32, we will have 8 batches.\n",
    "t_dataset,t_labels = ProcessingData(\"validation\")\n",
    "t_data = NewsDataset(t_dataset,t_labels)\n",
    "ts = DataLoader(t_data, batch_size=32)\n",
    "for inpu,labels in ts:\n",
    "    print(inpu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Accuracy of the network on the testset: 62 %\n"
     ]
    }
   ],
   "source": [
    "# putting it altogether\n",
    "train_data,train_labels = ProcessingData(\"train\")\n",
    "test_data,test_labels = ProcessingData(\"test\")\n",
    "  \n",
    "train_dataset = NewsDataset(train_data,train_labels)    \n",
    "test_dataset = NewsDataset(test_data,test_labels)\n",
    "\n",
    "model = Classifier()\n",
    "\n",
    "train(model, train_dataset)\n",
    "test(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEXT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9771d572cfe1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Load data from torchtext (identical to what we have in Kaggle)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMDB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TEXT' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sentencepiece as spm\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "#import spacy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# Load data from torchtext (identical to what we have in Kaggle)\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "train_data, valid_data = train_data.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
